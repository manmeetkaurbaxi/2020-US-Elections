{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrwLn-47J49u"
      },
      "outputs": [],
      "source": [
        "# !pip install spark-nlp -q\n",
        "# !pip install pyspark -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj8X8taKKG0t",
        "outputId": "6a038a69-26e9-4a43-d4f7-d8116c8a6319"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Necessary imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier, LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "import shutil\n",
        "\n",
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.types import *\n",
        "from pyspark import SparkContext, SQLContext\n",
        "\n",
        "LABEL_IDS = {'FAVOUR': 0, 'AGAINST': 1, 'NEUTRAL': 2}\n",
        "N_LABELS = len(LABEL_IDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDboKkxIKcDB"
      },
      "outputs": [],
      "source": [
        "stance_df = pd.read_csv('labelled_stance_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgdVYb4JKv-Z",
        "outputId": "b8ea2a7b-473f-4af7-a795-2a22f4461376"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3015, 46)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stance_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqfMVNmtPogP"
      },
      "source": [
        "### Hashing Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4my4uIQ4NUkJ",
        "outputId": "3050aef9-621c-4556-867f-1c62232d175b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2110, 46) (905, 46)\n",
            "(2110,) (2110,) (905,) (905,)\n"
          ]
        }
      ],
      "source": [
        "train_df, test_df = train_test_split(stance_df, test_size=0.3)\n",
        "print(train_df.shape, test_df.shape)\n",
        "\n",
        "x_train = train_df['tweet']\n",
        "y_train = train_df['stance']\n",
        "\n",
        "x_test = test_df['tweet']\n",
        "y_test = test_df['stance']\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUqoS96IP1ZO"
      },
      "outputs": [],
      "source": [
        "# Convert tweets into Vectors\n",
        "hashingVectorizer = HashingVectorizer(stop_words='english', alternate_sign=False)\n",
        "hashingVectorizer.fit(x_train)\n",
        "x_train_new = hashingVectorizer.transform(x_train)\n",
        "x_test_new = hashingVectorizer.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-OsR9M2QWPn",
        "outputId": "9eba5fad-6a37-480e-863f-32423962c0a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Oversampling\n",
        "smote = SMOTE()\n",
        "ov_train_x, ov_train_y = smote.fit_resample(x_train_new, y_train)\n",
        "ov_test_x, ov_test_y = smote.fit_resample(x_test_new, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE3h0tNDQeSa",
        "outputId": "7218f5bf-3f99-4c7b-9f12-dc4752296caf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for Linear SVM with Hashing Vectorizer: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.57      0.33      0.42        76\n",
            "      FAVOUR       0.76      0.90      0.82       651\n",
            "     NEUTRAL       0.30      0.16      0.21       178\n",
            "\n",
            "    accuracy                           0.70       905\n",
            "   macro avg       0.54      0.46      0.48       905\n",
            "weighted avg       0.66      0.70      0.67       905\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Linear SVM\n",
        "linearSVM = LinearSVC()\n",
        "linearSVM.fit(x_train_new, y_train)\n",
        "y_pred_lsvm = linearSVM.predict(x_test_new)\n",
        "\n",
        "print('Classification Report for Linear SVM with Hashing Vectorizer: \\n', metrics.classification_report(y_test, y_pred_lsvm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0Cw3iaJZoQl",
        "outputId": "f80f23b9-37f4-45c2-c8ab-387afaea4b26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for Linear SVM with Hashing Vectorizer & Oversampling: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.83      0.52      0.64       651\n",
            "      FAVOUR       0.47      0.78      0.59       651\n",
            "     NEUTRAL       0.44      0.31      0.36       651\n",
            "\n",
            "    accuracy                           0.54      1953\n",
            "   macro avg       0.58      0.54      0.53      1953\n",
            "weighted avg       0.58      0.54      0.53      1953\n",
            "\n"
          ]
        }
      ],
      "source": [
        "linearSVM.fit(ov_train_x, ov_train_y)\n",
        "y_pred_lsvm = linearSVM.predict(ov_test_x)\n",
        "\n",
        "print('Classification Report for Linear SVM with Hashing Vectorizer & Oversampling: \\n', metrics.classification_report(ov_test_y, y_pred_lsvm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgUWoKx1RAHt",
        "outputId": "0ce2d40a-8f61-46e9-de6a-799ff9db302a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for SVM with Hashing Vectorizer: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      0.20      0.31        76\n",
            "      FAVOUR       0.73      0.99      0.84       651\n",
            "     NEUTRAL       0.22      0.01      0.02       178\n",
            "\n",
            "    accuracy                           0.73       905\n",
            "   macro avg       0.55      0.40      0.39       905\n",
            "weighted avg       0.63      0.73      0.64       905\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Linear SVM\n",
        "svm = SVC()\n",
        "svm.fit(x_train_new, y_train)\n",
        "y_pred_lsvm = svm.predict(x_test_new)\n",
        "\n",
        "print('Classification Report for SVM with Hashing Vectorizer: \\n', metrics.classification_report(y_test, y_pred_lsvm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzslnpcwZfyV",
        "outputId": "d7acc861-7310-4bdf-98aa-f43127029a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for SVM with Hashing Vectorizer & Oversampling: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.93      0.53      0.68       651\n",
            "      FAVOUR       0.58      0.98      0.73       651\n",
            "     NEUTRAL       0.64      0.47      0.54       651\n",
            "\n",
            "    accuracy                           0.66      1953\n",
            "   macro avg       0.72      0.66      0.65      1953\n",
            "weighted avg       0.72      0.66      0.65      1953\n",
            "\n"
          ]
        }
      ],
      "source": [
        "svm.fit(ov_train_x, ov_train_y)\n",
        "y_pred_lsvm = svm.predict(ov_test_x)\n",
        "\n",
        "print('Classification Report for SVM with Hashing Vectorizer & Oversampling: \\n', metrics.classification_report(ov_test_y, y_pred_lsvm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECjaCIIQRnEO",
        "outputId": "98b8180c-5f64-4374-c813-329c25f0d67e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for Logistic Regression with Hashing Vectorizer: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.24      0.36        76\n",
            "      FAVOUR       0.74      0.97      0.84       651\n",
            "     NEUTRAL       0.30      0.06      0.09       178\n",
            "\n",
            "    accuracy                           0.73       905\n",
            "   macro avg       0.59      0.42      0.43       905\n",
            "weighted avg       0.66      0.73      0.65       905\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "logisticRegression = LogisticRegression()\n",
        "logisticRegression.fit(x_train_new, y_train)\n",
        "y_pred_lr = logisticRegression.predict(x_test_new)\n",
        "\n",
        "print('Classification Report for Logistic Regression with Hashing Vectorizer: \\n', metrics.classification_report(y_test, y_pred_lr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h94BDretY-UF",
        "outputId": "9a9cf784-c13d-47ef-dfa0-272958fae0b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for Logistic Regression with Hashing Vectorizer & OverSampling: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.84      0.61      0.71       651\n",
            "      FAVOUR       0.48      0.75      0.59       651\n",
            "     NEUTRAL       0.46      0.34      0.39       651\n",
            "\n",
            "    accuracy                           0.57      1953\n",
            "   macro avg       0.60      0.57      0.56      1953\n",
            "weighted avg       0.60      0.57      0.56      1953\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "logisticRegression = LogisticRegression()\n",
        "logisticRegression.fit(ov_train_x, ov_train_y)\n",
        "y_pred_lr = logisticRegression.predict(ov_test_x)\n",
        "\n",
        "print('Classification Report for Logistic Regression with Hashing Vectorizer & OverSampling: \\n', metrics.classification_report(ov_test_y, y_pred_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn59oeeqSKJS"
      },
      "source": [
        "### TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR14I4ZfR_AC"
      },
      "outputs": [],
      "source": [
        "tfidf_vec = TfidfVectorizer(max_features=300)\n",
        "tfidf_vec.fit(x_train)\n",
        "x_train_tfidf = tfidf_vec.transform(x_train)\n",
        "x_test_tfidf = tfidf_vec.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQJqSJdwZ23O",
        "outputId": "ccb7e7c6-c80c-42e5-ce36-31fcf20de6b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "ov_train_x_tfidf, ov_train_y_tfidf = smote.fit_resample(x_train_tfidf, y_train)\n",
        "ov_test_x_tfidf, ov_test_y_tfidf = smote.fit_resample(x_test_tfidf, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xDeQH-JSeNR",
        "outputId": "9a8288e2-c78a-4e80-bf2e-1c14e9a7260a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for Linear SVM with TF-IDF: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.55      0.38      0.45        76\n",
            "      FAVOUR       0.77      0.92      0.84       651\n",
            "     NEUTRAL       0.36      0.14      0.20       178\n",
            "\n",
            "    accuracy                           0.72       905\n",
            "   macro avg       0.56      0.48      0.50       905\n",
            "weighted avg       0.67      0.72      0.68       905\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Linear SVM\n",
        "linearSVM = LinearSVC()\n",
        "linearSVM.fit(x_train_tfidf, y_train)\n",
        "y_pred_lsvm = linearSVM.predict(x_test_tfidf)\n",
        "\n",
        "print('Classification Report for Linear SVM with TF-IDF: \\n', metrics.classification_report(y_test, y_pred_lsvm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfOMoAyAaFjA",
        "outputId": "10b20c2a-a3ef-476b-bd51-43cd69ac0b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for Linear SVM with TF-IDF & Oversampling: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      0.63      0.66       651\n",
            "      FAVOUR       0.49      0.61      0.54       651\n",
            "     NEUTRAL       0.47      0.39      0.42       651\n",
            "\n",
            "    accuracy                           0.54      1953\n",
            "   macro avg       0.55      0.54      0.54      1953\n",
            "weighted avg       0.55      0.54      0.54      1953\n",
            "\n"
          ]
        }
      ],
      "source": [
        "linearSVM.fit(ov_train_x_tfidf, ov_train_y_tfidf)\n",
        "y_pred_lsvm = linearSVM.predict(ov_test_x_tfidf)\n",
        "\n",
        "print('Classification Report for Linear SVM with TF-IDF & Oversampling: \\n', metrics.classification_report(ov_test_y_tfidf, y_pred_lsvm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOPnHFYgSxZ7",
        "outputId": "ee4ab6a0-2329-47aa-d467-80cf0318e36b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for SVM with TF-IDF: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.28      0.40        76\n",
            "      FAVOUR       0.74      0.98      0.85       651\n",
            "     NEUTRAL       0.31      0.02      0.04       178\n",
            "\n",
            "    accuracy                           0.73       905\n",
            "   macro avg       0.59      0.43      0.43       905\n",
            "weighted avg       0.65      0.73      0.65       905\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# SVM\n",
        "svm = SVC()\n",
        "svm.fit(x_train_tfidf, y_train)\n",
        "y_pred = svm.predict(x_test_tfidf)\n",
        "\n",
        "print('Classification Report for SVM with TF-IDF: \\n', metrics.classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS8L9O5saOG5",
        "outputId": "426ff3b6-c9bf-4e1d-d18f-d9cc12477055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for SVM with TF-IDF & Oversampling: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.84      0.61      0.71       651\n",
            "      FAVOUR       0.58      0.95      0.72       651\n",
            "     NEUTRAL       0.63      0.41      0.49       651\n",
            "\n",
            "    accuracy                           0.66      1953\n",
            "   macro avg       0.69      0.66      0.64      1953\n",
            "weighted avg       0.69      0.66      0.64      1953\n",
            "\n"
          ]
        }
      ],
      "source": [
        "svm.fit(ov_train_x_tfidf, ov_train_y_tfidf)\n",
        "y_pred = svm.predict(ov_test_x_tfidf)\n",
        "\n",
        "print('Classification Report for SVM with TF-IDF & Oversampling: \\n', metrics.classification_report(ov_test_y_tfidf, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE9GdUtlS4MR",
        "outputId": "e0ac45bc-4348-42c6-9814-af057f641922"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for Logistic Regression with TF-IDF: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.24      0.36        76\n",
            "      FAVOUR       0.74      0.97      0.84       651\n",
            "     NEUTRAL       0.30      0.06      0.09       178\n",
            "\n",
            "    accuracy                           0.73       905\n",
            "   macro avg       0.59      0.42      0.43       905\n",
            "weighted avg       0.66      0.73      0.65       905\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "logisticRegression = LogisticRegression()\n",
        "logisticRegression.fit(x_train_new, y_train)\n",
        "y_pred_lr = logisticRegression.predict(x_test_new)\n",
        "\n",
        "print('Classification Report for Logistic Regression with TF-IDF: \\n', metrics.classification_report(y_test, y_pred_lr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gIt6WKlabvG",
        "outputId": "1d642f0f-e7af-4eba-fe1b-b3dfaa6af457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for Logistic Regression with TF-IDF & Oversampling: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.71      0.66      0.69       651\n",
            "      FAVOUR       0.49      0.63      0.56       651\n",
            "     NEUTRAL       0.48      0.38      0.43       651\n",
            "\n",
            "    accuracy                           0.56      1953\n",
            "   macro avg       0.56      0.56      0.56      1953\n",
            "weighted avg       0.56      0.56      0.56      1953\n",
            "\n"
          ]
        }
      ],
      "source": [
        "logisticRegression.fit(ov_train_x_tfidf, ov_train_y_tfidf)\n",
        "y_pred_lr = logisticRegression.predict(ov_test_x_tfidf)\n",
        "\n",
        "print('Classification Report for Logistic Regression with TF-IDF & Oversampling: \\n', metrics.classification_report(ov_test_y_tfidf, y_pred_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXVRaWZMTKC6"
      },
      "source": [
        "### Spark NLP (Universal Sentence Encoder & Classifier DL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pm_TFTRS-Qf"
      },
      "outputs": [],
      "source": [
        "sqlContext = SQLContext(SparkContext.getOrCreate())\n",
        "\n",
        "# Auxiliar functions\n",
        "def equivalent_type(f):\n",
        "    if f == 'datetime64[ns]': return TimestampType()\n",
        "    elif f == 'int64': return LongType()\n",
        "    elif f == 'int32': return IntegerType()\n",
        "    elif f == 'float64': return FloatType()\n",
        "    else: return StringType()\n",
        "\n",
        "def define_structure(string, format_type):\n",
        "    try: typo = equivalent_type(format_type)\n",
        "    except: typo = StringType()\n",
        "    return StructField(string, typo)\n",
        "\n",
        "# Given pandas dataframe, it will return a spark's dataframe.\n",
        "def pandas_to_spark(pandas_df):\n",
        "    columns = list(pandas_df.columns)\n",
        "    types = list(pandas_df.dtypes)\n",
        "    struct_list = []\n",
        "    for column, typo in zip(columns, types): \n",
        "      struct_list.append(define_structure(column, typo))\n",
        "    p_schema = StructType(struct_list)\n",
        "    return sqlContext.createDataFrame(pandas_df, p_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pW2h6qUTQC0"
      },
      "outputs": [],
      "source": [
        "trainDataset = pandas_to_spark(train_df)\n",
        "testDataset = pandas_to_spark(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4htE46DTR_6",
        "outputId": "c8a80f7e-f3bd-4b70-fca9-2c3b24f57bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "# Get tweets\n",
        "document = DocumentAssembler().setInputCol('tweet').setOutputCol('tweet')\n",
        "\n",
        "# Download Universal Sentence Encoder\n",
        "use = UniversalSentenceEncoder.pretrained().setInputCols(['tweet']).setOutputCol('tweet_embeddings')\n",
        "\n",
        "# Classifier DL\n",
        "classifier_dl = ClassifierDLApproach().setInputCols(['tweet_embeddings']).setOutputCol('class').setLabelColumn('stance').setMaxEpochs(5).setEnableOutputLogs(True)\n",
        "\n",
        "use_clf_dl_pipeline = Pipeline(\n",
        "    stages=[\n",
        "            document,\n",
        "            use, classifier_dl\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNPdId-qTUVv"
      },
      "outputs": [],
      "source": [
        "use_pipeline_model = use_clf_dl_pipeline.fit(trainDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DpLGAPFTXBd",
        "outputId": "b96d82b1-7ae0-4e07-8723-e41a311fe3f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        76\n",
            "      FAVOUR       0.72      1.00      0.84       651\n",
            "     NEUTRAL       0.00      0.00      0.00       178\n",
            "\n",
            "    accuracy                           0.72       905\n",
            "   macro avg       0.24      0.33      0.28       905\n",
            "weighted avg       0.52      0.72      0.60       905\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "preds = use_pipeline_model.transform(testDataset)\n",
        "\n",
        "pred_df = use_pipeline_model.transform(testDataset).select('stance','tweet','class.result').toPandas()\n",
        "\n",
        "pred_df['result'] = pred_df['result'].apply(lambda x:x[0])\n",
        "\n",
        "print(metrics.classification_report(pred_df.stance, pred_df.result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osj5Xo5gTYyi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Stance Detection (Baselines).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
