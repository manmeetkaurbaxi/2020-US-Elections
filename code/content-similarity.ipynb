{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from statistics import mean\n",
    "nltk.download('stopwords')\n",
    "DEM_PATH = '../../data/twitter/raw/users/democrats/required/'\n",
    "REP_PATH = '../../data/twitter/raw/users/republicans/required/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to flatten column (in the form of list of lists) into a list\n",
    "def flatten2dList(df, column):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        df:     dataframe to be processed\n",
    "        column: column from the dataframe to be flattened\n",
    "    Returns:\n",
    "        series: A series object of the flattened column\n",
    "    \"\"\"\n",
    "    list_2d = list(filter(lambda i: i!='[]', df[column].tolist()))\n",
    "    series = []\n",
    "    for sublist in list_2d:\n",
    "        sublist = ast.literal_eval(sublist)\n",
    "        for i in sublist:\n",
    "            series.append(i)\n",
    "    # series = Series(series)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(matrix, tokens):\n",
    "    doc_names = [f'doc_{i+1}' for i, _ in enumerate(matrix)]\n",
    "    df = pd.DataFrame(data=matrix, index=doc_names, columns=tokens)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "stopWords = stopwords.words('english')\n",
    "additionalStopwords = ['http','https','amp','CO','Trump','Trump2016','Donald','Clinton','Hillary','realDonaldTrump','will','say','said','let','vote','now','go','today','thanks','thank']\n",
    "stopWords.extend(additionalStopwords)\n",
    "stopWords = set(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculateJaccardSimilarity(username1, username2):\n",
    "#     \"\"\"\n",
    "#     Calculates the Jaccard Similarity Score between two twitter users on the basis of tweets.\n",
    "#     Inputs:\n",
    "#         username1, username2: usernames of the two users\n",
    "#     Output: Jaccard Similarity Score for tweets\n",
    "#     \"\"\"\n",
    "#     user1_df = pd.read_csv(REP_PATH+username1+'.csv')\n",
    "#     if isinstance(username2, list):\n",
    "#         user2_listOfDataframes = []\n",
    "#         for users in username2:\n",
    "#             user2_df = pd.read_csv(REP_PATH+users+'.csv')\n",
    "#             user2_listOfDataframes.append(user2_df)\n",
    "#         user2_df = pd.concat(user2_listOfDataframes)\n",
    "#     else:\n",
    "#         user2_df = pd.read_csv(REP_PATH+username2+'.csv')\n",
    "\n",
    "#     # Calculate Jaccard Similarity on Tweets\n",
    "#     user1_tweets = ((user1_df.tweet.values).astype('str')).tolist()\n",
    "#     user2_tweets = ((user2_df.tweet.values).astype('str')).tolist()\n",
    "    \n",
    "#     jaccardSimilarityList = []\n",
    "    \n",
    "#     for user1_tweet in user1_tweets:\n",
    "#         query_tw = user1_tweet\n",
    "#         query_words = set(query_tw.split())\n",
    "#         filtered_query_words = set([w for w in query_words if w not in stopWords])\n",
    "        \n",
    "#         maxJaccardSimList = []\n",
    "        \n",
    "#         for user2_tweet in user2_tweets:\n",
    "#             user2_words = set(user2_tweet.split())\n",
    "#             # filtered_user2_words = set([w for w in user2_words if w not in stopWords])\n",
    "            \n",
    "#             jaccardSimQuery = round(len(query_words.intersection(user2_words))/len(query_words.union(user2_words)), 7)\n",
    "        \n",
    "#             maxJaccardSimList.append(jaccardSimQuery)\n",
    "            \n",
    "#         maxJaccardSim = max(maxJaccardSimList)\n",
    "#         jaccardSimilarityList.append(maxJaccardSim)\n",
    "        \n",
    "#     avgJaccardSimilarity = mean(jaccardSimilarityList)  \n",
    "    \n",
    "#     return avgJaccardSimilarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCosineSimilarity(username1, username2):\n",
    "# def calculateCosineSimilarity(username1, username2, fromDate, toDate):\n",
    "    \"\"\"\n",
    "    Calculates the Cosine Similarity Score between two twitter users on tweets.\n",
    "    Inputs:\n",
    "        username1, username2: usernames of the two users\n",
    "    Output: Cosine Similarity Score for tweets\n",
    "    \"\"\"\n",
    "    user1_df = pd.read_csv(DEM_PATH + username1 + '.csv')\n",
    "    if isinstance(username2, list):\n",
    "        user2_listOfDataframes = []\n",
    "        for users in username2:\n",
    "            user2_df = pd.read_csv(DEM_PATH + users + '.csv')\n",
    "            user2_listOfDataframes.append(user2_df)\n",
    "        user2_df = pd.concat(user2_listOfDataframes)\n",
    "    else:\n",
    "        user2_df = pd.read_csv(DEM_PATH + username2 + '.csv')\n",
    "    \n",
    "\n",
    "    # Calculate Cosine Similarity on Tweets\n",
    "    user1_tweets = ((user1_df.tweet.values).astype('str')).tolist()\n",
    "    user2_tweets = ((user2_df.tweet.values).astype('str')).tolist()\n",
    "    user1_embeddings = model.encode(user1_tweets, convert_to_tensor=True)\n",
    "    user2_embeddings = model.encode(user2_tweets, convert_to_tensor=True)\n",
    "    cosineSim = []\n",
    "    for user1_embedding in user1_embeddings:\n",
    "      cosine_scores = (util.pytorch_cos_sim(user1_embedding, user2_embeddings[:])).tolist()[0]\n",
    "\n",
    "      maxScore = max(cosine_scores)\n",
    "\n",
    "      cosineSim.append(maxScore)      \n",
    "\n",
    "    avgCosineSim = mean(cosineSim)\n",
    "    return avgCosineSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate1 = 'realDonaldTrump'\n",
    "candidate2 = 'HouseGOP'\n",
    "# jsTweets = calculateJaccardSimilarity(candidate1, candidate2)\n",
    "csTweets = calculateCosineSimilarity(candidate1, candidate2)\n",
    "\n",
    "print(candidate1, 'VS', candidate2, sep=' ')\n",
    "# print('Jaccard Similarity for Tweets:', jsTweets)\n",
    "print('Cosine Similarity for Tweets:', csTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f3b078249380ea762697f4f8f6aea77b3d6e43cbb1b18cbb73d8cde5aa597e7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
